# ðŸ§  LLMs From Scratch â€” My Personal Deep Dive

This repository is my **learning lab for building, training, and understanding large language models (LLMs)** from the ground up.  
Everything here is coded manually â€” no shortcuts, no black boxes â€” to deeply understand how transformers, tokenizers, optimizers, and distributed training truly work.

---

## ðŸ“– Overview

Iâ€™m implementing and experimenting with different LLM architectures, attention mechanisms, and modern model designs that keep appearing in research and open-source projects. The goal is simple â€” to understand how these models actually work by building them myself, one at a time.


---